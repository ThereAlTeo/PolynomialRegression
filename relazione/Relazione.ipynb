{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Progetto di Applicazioni Data Intensive 2018/2019\n",
    "\n",
    "\n",
    "__Orazi Filippo 0000801069__\n",
    "\n",
    "__Alesiani Matteo 0000806466__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descrizione del problema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il problema da noi analizzato si pone l'obbiettivo di prevedere per conto di una società che effettua bike sharing (ossia una forma di affitto di biciclette automatizzato) il numero di biciclette che saranno affittate durante una giornata che presenta determinate caratteristiche."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il dataset denominato \"Bike Sharing Data Set\" è stato scaricato dal sito https://archive.ics.uci.edu/ml e si compone di 731 istanze, 16 diversi attributi di cui 2 identificatori e 3 possibili soggetti di predizione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib  inline\n",
    "import os.path\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "if os.path.exists(\"day.csv\"):\n",
    "    ds = pd.read_csv(\"day.csv\", sep=\",\")\n",
    "else:\n",
    "    print(\"File non trovato\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descrizione variabili\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il dataset scelto presenta variabili strutturate, ovvero i cui valori sono noti.\n",
    "\n",
    "Vengono di seguito descritte:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __instant__: indice dei record.<br>\n",
    "- __dteday__: data.<br>\n",
    "- __season__: stagione<br>\n",
    "- __yr__:  anno (0: 2011, 1: 2012) <br> \n",
    "- __mnth__: mese (1 - 12) <br>\n",
    "- __holiday__: giorno festivo (1: si, 0: no)<br>\n",
    "- __weekday__: giorno della settimana (0 - 6)<br>\n",
    "- __workingaday__: se il giorno è festivo o appartiene al weekend 0, altrimenti 1<br>\n",
    "- __wheathersit__: condizioni meteo generali della giornata:\n",
    "  * 1: soleggiato, poco nuvoloso\n",
    "  * 2: nuvoloso, nebbia\n",
    "  * 3: leggera neve, leggera pioggia\n",
    "  * 4: neve, pioggia, fulmini <br> \n",
    "\n",
    "- __temp__: temperatura media giornaliera (C) normalizzata. Valori divisi per 41. <br>\n",
    "- __atemp__: temperatura perepita (°C) normaizzata. Valori divisi per 50<br>\n",
    "- __hum__: percentuale di umidità<br>\n",
    "- __windspeed__: velocità del vento normalizzata, Valori divisi per 67. <br>\n",
    "- __casual__: numero di utenti casuali<br>\n",
    "- __registered__: numero di utenti registrati<br>\n",
    "- __cnt__: numero di utenti totali<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La variabile scelta come oggeto di predizione è la variabile \"cnt\" in quanto a fini di ricerca di mercato è la variabile che più interessa. Vengono qundi esclusi gli attributi \"casual\" e \"registered\", di cui \"cnt\" è la somma, e le relative colonne.\n",
    "\n",
    "Osserviamo come la variabile da predire sia di tipo continuo. La metodologia utilizzata, per la risoluzione del problema, attua un algoritmo di regressione. \n",
    "\n",
    "Concludianmo la descrizione delle variabili definendo come indice del dataframe l'attrbuto \"dteday\" e eliminando \"instant\", poichè svolge la stessa funzione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.set_index([\"dteday\"], inplace=True)\n",
    "dataset = ds.drop([\"casual\", \"registered\",\"instant\"], axis=1)\n",
    "Y = dataset[\"cnt\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisi esplorativa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il compito dell'analisi esplorativa consiste nel identificare nel dataset le caratteristiche degli attirbuti (feature) che possono influenzare la creazione del modello, ad esempio la presenza di valori nulli comporterebbe l'esigenza di attuare contromisure volte alla loro gestione. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Altro compito dell'analisi sta nel rappresentare l'insieme dei dati attraveso indici di correlazione tra variabili, grafici e descizioni matematiche."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possiamo ottenere un inisieme di descrittori matematici dei vari attibuti attraverso la funzione _describe_.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>731.000000</td>\n",
       "      <td>731.000000</td>\n",
       "      <td>731.000000</td>\n",
       "      <td>731.000000</td>\n",
       "      <td>731.000000</td>\n",
       "      <td>731.000000</td>\n",
       "      <td>731.000000</td>\n",
       "      <td>731.000000</td>\n",
       "      <td>731.000000</td>\n",
       "      <td>731.000000</td>\n",
       "      <td>731.000000</td>\n",
       "      <td>731.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.496580</td>\n",
       "      <td>0.500684</td>\n",
       "      <td>6.519836</td>\n",
       "      <td>0.028728</td>\n",
       "      <td>2.997264</td>\n",
       "      <td>0.683995</td>\n",
       "      <td>1.395349</td>\n",
       "      <td>0.495385</td>\n",
       "      <td>0.474354</td>\n",
       "      <td>0.627894</td>\n",
       "      <td>0.190486</td>\n",
       "      <td>4504.348837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.110807</td>\n",
       "      <td>0.500342</td>\n",
       "      <td>3.451913</td>\n",
       "      <td>0.167155</td>\n",
       "      <td>2.004787</td>\n",
       "      <td>0.465233</td>\n",
       "      <td>0.544894</td>\n",
       "      <td>0.183051</td>\n",
       "      <td>0.162961</td>\n",
       "      <td>0.142429</td>\n",
       "      <td>0.077498</td>\n",
       "      <td>1937.211452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.059130</td>\n",
       "      <td>0.079070</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022392</td>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.337083</td>\n",
       "      <td>0.337842</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.134950</td>\n",
       "      <td>3152.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.498333</td>\n",
       "      <td>0.486733</td>\n",
       "      <td>0.626667</td>\n",
       "      <td>0.180975</td>\n",
       "      <td>4548.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.655417</td>\n",
       "      <td>0.608602</td>\n",
       "      <td>0.730209</td>\n",
       "      <td>0.233214</td>\n",
       "      <td>5956.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.861667</td>\n",
       "      <td>0.840896</td>\n",
       "      <td>0.972500</td>\n",
       "      <td>0.507463</td>\n",
       "      <td>8714.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           season          yr        mnth     holiday     weekday  workingday  \\\n",
       "count  731.000000  731.000000  731.000000  731.000000  731.000000  731.000000   \n",
       "mean     2.496580    0.500684    6.519836    0.028728    2.997264    0.683995   \n",
       "std      1.110807    0.500342    3.451913    0.167155    2.004787    0.465233   \n",
       "min      1.000000    0.000000    1.000000    0.000000    0.000000    0.000000   \n",
       "25%      2.000000    0.000000    4.000000    0.000000    1.000000    0.000000   \n",
       "50%      3.000000    1.000000    7.000000    0.000000    3.000000    1.000000   \n",
       "75%      3.000000    1.000000   10.000000    0.000000    5.000000    1.000000   \n",
       "max      4.000000    1.000000   12.000000    1.000000    6.000000    1.000000   \n",
       "\n",
       "       weathersit        temp       atemp         hum   windspeed          cnt  \n",
       "count  731.000000  731.000000  731.000000  731.000000  731.000000   731.000000  \n",
       "mean     1.395349    0.495385    0.474354    0.627894    0.190486  4504.348837  \n",
       "std      0.544894    0.183051    0.162961    0.142429    0.077498  1937.211452  \n",
       "min      1.000000    0.059130    0.079070    0.000000    0.022392    22.000000  \n",
       "25%      1.000000    0.337083    0.337842    0.520000    0.134950  3152.000000  \n",
       "50%      1.000000    0.498333    0.486733    0.626667    0.180975  4548.000000  \n",
       "75%      2.000000    0.655417    0.608602    0.730209    0.233214  5956.000000  \n",
       "max      3.000000    0.861667    0.840896    0.972500    0.507463  8714.000000  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La Funzione _info_ di _pandas.Dataframe_ permette di conoscere un ulteriore insieme di informazioni del dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 731 entries, 2011-01-01 to 2012-12-31\n",
      "Data columns (total 12 columns):\n",
      "season        731 non-null int64\n",
      "yr            731 non-null int64\n",
      "mnth          731 non-null int64\n",
      "holiday       731 non-null int64\n",
      "weekday       731 non-null int64\n",
      "workingday    731 non-null int64\n",
      "weathersit    731 non-null int64\n",
      "temp          731 non-null float64\n",
      "atemp         731 non-null float64\n",
      "hum           731 non-null float64\n",
      "windspeed     731 non-null float64\n",
      "cnt           731 non-null int64\n",
      "dtypes: float64(4), int64(8)\n",
      "memory usage: 116.4 KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info(memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proseguiamo l'analisi del Dataset verificando la correlazione che l'attributo da predire ha in relazione agli altri. La correlazione di due variabili casuali X e Y, è dato dal rapporto tra la loro covarianza σXY e il prodotto delle deviazioni standard σX e σY\n",
    "ρ(X,Y)= σXYσXσY\n",
    "\n",
    "Il coefficiente ha un valore compreso tra 1 e -1, dove\n",
    "valori vicini a 1 indicano correlazione diretta (Y cresce al crescere di X)\n",
    "valori vicini a -1 indicano correlazione inversa (Y descresce al crescere di X)\n",
    "valori vicini a 0 indicano assenza di correlazione\n",
    "\n",
    "Le seguanti funzioni consentono di calcolare la correlazione tra due serie e il grafico relativo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def getCorrelation(feature1, feature2):\n",
    "    return np.mean((feature1-feature1.mean()) * (feature2-feature2.mean())) / (feature1.std() * feature2.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plot\n",
    "def plotData(x, y, XAxisName, YAxisName):\n",
    "    plot.scatter(x, y)\n",
    "    plot.grid()\n",
    "    plot.xlabel(XAxisName); plot.ylabel(YAxisName)\n",
    "    plot.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mentre con la seguente si può ottenere una serie ordinata che indica la correlazione tra \"cnt\" e il nostro dataset indicizzato su \"dtaday\", un histogramma di ogni attributo, e un grafico a dispersione di ogni feature con l'obbiettivo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlationRank(dataset, feature):\n",
    "    correlation = []\n",
    "    for a in dataset.columns:\n",
    "        correlation.append(getCorrelation(dataset[a].astype(\"float\"), feature))\n",
    "        plotData(dataset[a].astype(\"float\"), feature, a, \"Byke Rent\")\n",
    "    cor = pd.Series(correlation, dataset.columns)\n",
    "    cor.sort_values(ascending=False, inplace=True)\n",
    "    return cor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor = correlationRank(dataset.drop([\"cnt\"], axis=1),dataset[\"cnt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dai grafici e dal calcolo della correlazione scopriamo che gli attributi weekday workingday e holiday sono attributi poco importanti per il calcolo.\n",
    "Nonostante ciò essendo la correlazione un calcolo su un coefficente di primo grado questi attributi poco correlati non vengono esclusi dal calcolo in quanto questo si baserà verosimilmente su un algoritmo polinomiale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preaparazione dei dati"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Molti dei dati sono già stati standardizzati alla creazione del dataset, i dati che normalmente vengono presentati come categorici sono già forniti in forma numerica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I dati che necessitano di standardidazione verranno elaborati successivamente in ogni Pipeline attraverso la funzione di sklearn _StandardScaler_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "essendo questo un problema di regressione calcoliamo con la norma L1 le feature più rilevanti ma prima dividiamo il dataset in trainSet e ValidationSet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Y = dataset[\"cnt\"]\n",
    "X = dataset.drop([\"cnt\"], axis=1)\n",
    "XTrain, XVal, YTrain, YVal = train_test_split(X, Y, test_size=0.33, random_state=73)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "def elaborationWithLasso(degeePipe=1, alphaPipe=0):\n",
    "    return Pipeline([(\"poly\", PolynomialFeatures(degree=degeePipe, include_bias=False)),\n",
    "                    (\"scale\",  StandardScaler()),\n",
    "                    (\"linreg\", Lasso(alpha=alphaPipe, max_iter=6000, tol=0.005))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showZerosFeatures(XTrain, YTrain):\n",
    "    model = elaborationWithLasso(1, 2)\n",
    "    model.fit(XTrain, YTrain)\n",
    "    tmp = pd.Series(model.named_steps[\"linreg\"].coef_, XTrain.columns)\n",
    "    print(tmp)\n",
    "    a = []\n",
    "    for row in tmp.index:\n",
    "        if(tmp[row]==0):\n",
    "            a.append(row)\n",
    "    print(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showZerosFeatures(XTrain, YTrain)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prima di decidere se mantenere o no la colonna \"temp\" valutiamo la bontà del modello attraverso il calcolo del coefficiente $R^2$, dell' errore relativo e dell'errore quadratico medio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relativeError(YTrue, YPred):\n",
    "    return np.mean(np.abs((YTrue - YPred) / YTrue))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "def printEvalutation(X, Y, model):\n",
    "    print(\"Mean squared error    : {:.5}\".format(mean_squared_error(model.predict(X), Y)))\n",
    "    print(\"Relative error        : {:.5%}\".format(relativeError(model.predict(X), Y)))\n",
    "    print(\"R-squared coefficient : {:.5}\".format(model.score(X, Y)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = elaborationWithLasso(6, 8)\n",
    "model.fit(XTrain, YTrain)\n",
    "printEvalutation(XVal, YVal, model)\n",
    "#model.named_steps[\"linreg\"].coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il risultato è buono ma sono possibili miglioramenti per cui non andremo ad escludere manualmente gli attributi che la norma L1 azzera ma piuttosto riuseremo la norma successivamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generazione modelli di learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generiamo adesso diversi modelli di learning utilizzando k (nested) cross fold validation applicata ad una grid search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definiamo innanzitutto le pipeline di ogni modello.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il modello Ridge è un modello di regressione lineare che applica $ \\Vert \\theta \\Vert_2^2 = \\sum_{i=1}^n  \\theta _i ^2$ ossia la norma l2 in modo da regolarizzare le dimensioni dei coefficienti del modello.\n",
    "Questo permette di ridurre le oscillazione ed aumentare l'accuratezza del modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "def elaborationWithRidge():\n",
    "    return Pipeline([(\"poly\", PolynomialFeatures(include_bias=False)),\n",
    "                    (\"scale\",  StandardScaler()),   \n",
    "                    (\"linreg\", Ridge())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il modello Elastic Net è un modello di regressione lineare che applica si la norma l1 sia la norma l2 in questo modo $ \\alpha \\Vert \\theta \\Vert_1 + (1 - \\alpha) \\Vert \\theta \\Vert_2$.\n",
    "l'iperparametro $\\alpha$ indica quanto il modello è \"sbilanciato verso la norma L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "def elaborationWithElasticNet():\n",
    "    return Pipeline([(\"poly\",   PolynomialFeatures(include_bias=False)),\n",
    "                     (\"scale\",  StandardScaler()),\n",
    "                     (\"linreg\",  ElasticNet(tol = 0.05, max_iter = 6000))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creiamo anche un modello di regressione lineare senza restrizioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def elaborationWithoutRestrain():\n",
    "    return Pipeline([(\"poly\",  PolynomialFeatures(include_bias=False)),\n",
    "                    (\"scale\",  StandardScaler()),\n",
    "                    (\"linreg\", LinearRegression())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ora definiamo il grado e gli iperparametri migliori attraverso una gridsearch con cross validation e addestriamo i modelli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parRidge = {\n",
    "    \"poly__degree\": [1,6,8],\n",
    "    \"linreg__alpha\":  [1,2,6]\n",
    "}\n",
    "model = elaborationWithRidge()\n",
    "ridgeGridSearch = GridSearchCV(model, param_grid=parRidge)\n",
    "ridgeGridSearch.fit(XTrain, YTrain)\n",
    "print(ridgeGridSearch.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parLasso = {\n",
    "    \"poly__degree\": [1,6,8],\n",
    "    \"linreg__alpha\":  [1,5,8]\n",
    "}\n",
    "LassoModel = elaborationWithLasso()\n",
    "lassoGridSearch = GridSearchCV(LassoModel, param_grid=parLasso)\n",
    "lassoGridSearch.fit(XTrain, YTrain)\n",
    "print(lassoGridSearch.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parNet = {\n",
    "    \"poly__degree\": [1,2,6],\n",
    "    \"linreg__alpha\": [1,2,8],\n",
    "    \"linreg__l1_ratio\": [0.1, 0.5, 1.0]\n",
    "}\n",
    "NETmodel = elaborationWithElasticNet()\n",
    "gs = GridSearchCV(NETmodel, param_grid=parNet)\n",
    "gs.fit(XTrain, YTrain)\n",
    "print(gs.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parNR = {\n",
    "   \"poly__degree\": [1,2],\n",
    "}\n",
    "NRmodel = elaborationWithoutRestrain()\n",
    "NRGridSearch = GridSearchCV(NRmodel, param_grid=parNR)\n",
    "NRGridSearch.fit(XTrain, YTrain)\n",
    "print(NRGridSearch.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valutazione modelli\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valutiamo ora i modelli ricavati nel punto precedente attraverso le metriche gia introdotte di $R^2$, errore relativo e errore quadratico medio. aggiungiamo alla valutazione una tabella ottenuta attraverso l'attributo *cv_results* di _GridSearchCV_ in modo da verificare quali parametri hanno portato un risultato migliore nei vari tipi di regressione. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EvalutationTable(results):\n",
    "    return pd.DataFrame(results.cv_results_).sort_values(\"mean_test_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printEvalutation(XVal, YVal, lassoGridSearch)\n",
    "EvalutationTable(lassoGridSearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printEvalutation(XVal, YVal, ridgeGridSearch)\n",
    "EvalutationTable(ridgeGridSearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printEvalutation(XVal, YVal, NRGridSearch)\n",
    "EvalutationTable(NRGridSearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printEvalutation(XVal, YVal, gs)\n",
    "EvalutationTable(gs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "definiamo come modelli migliori i seguenti: <br>\n",
    "* regressione con lasso di grado 6 e con $\\lambda$ = 8\n",
    "* regressione con lasso di grado 6 e con $\\lambda$ = 5\n",
    "* regressione con Elastic net di grado 6 con $\\lambda = 2$ e $\\alpha = 0.5$\n",
    " \n",
    "che presentano rispettivamente le seguenti metriche di giudizio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LassoModel1 = Pipeline([(\"poly\", PolynomialFeatures(degree=6, include_bias=False)),\n",
    "                        (\"scale\",  StandardScaler()),\n",
    "                        (\"linreg\", Lasso(alpha=8, max_iter=6000, tol=0.005))])\n",
    "print(\"LassoModel1\")\n",
    "LassoModel1.fit(XTrain, YTrain)\n",
    "count = 0\n",
    "for a in LassoModel1.named_steps[\"linreg\"].coef_ :\n",
    "    if a != 0:\n",
    "        count += 1\n",
    "print(count)\n",
    "printEvalutation(XVal, YVal, LassoModel1)\n",
    "\n",
    "print(\"\\nLassoModel2\")\n",
    "LassoModel2 = Pipeline([(\"poly\", PolynomialFeatures(degree=6, include_bias=False)),\n",
    "                        (\"scale\",  StandardScaler()),\n",
    "                        (\"linreg\", Lasso(alpha=5, max_iter=6000, tol=0.005))])\n",
    "LassoModel2.fit(XTrain, YTrain)\n",
    "count = 0\n",
    "for a in LassoModel2.named_steps[\"linreg\"].coef_ :\n",
    "    if a != 0:\n",
    "        count += 1\n",
    "print(count)\n",
    "\n",
    "printEvalutation(XVal, YVal, LassoModel2)\n",
    "\n",
    "print(\"\\nENModel\")\n",
    "ENModel = Pipeline([(\"poly\",   PolynomialFeatures(degree = 6, include_bias=False)),\n",
    "                     (\"scale\",  StandardScaler()),\n",
    "                     (\"linreg\",  ElasticNet(alpha=2, l1_ratio=0.5, tol = 0.05, max_iter = 6000))])\n",
    "ENModel.fit(XTrain, YTrain)\n",
    "count = 0\n",
    "for a in ENModel.named_steps[\"linreg\"].coef_ :\n",
    "    if a != 0:\n",
    "        count += 1\n",
    "print(count)\n",
    "\n",
    "printEvalutation(XVal, YVal, ENModel)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dei tre modelli complessivamente molto buoni, viene scartato il modello con ElasticNet perchè nel complesso presenta risultati peggiori. \n",
    "\n",
    "Dei due modelli che utilizzano il Lasso viene designato come migliore quello che presenta grado 6 e con $\\lambda$ = 8 perchè ottiene prestazioni migliori in tutte le metriche di giudizio.  \n",
    "Inoltre compie la propria elaborazione con un numero di coefficienti minore, ne consegue una elaborazione più efficente rispetto al carico computazionale. \n",
    "\n",
    "Infine è importante considerare che la diminuzione del numero di coefficienti può portare al fenomeno dell'overfitting, ossia la costruzione di un modello troppo aderente al training set con un apparente aumento della qualità della previsione.\n",
    "Un Modello così sviluppato potrebbe non risultare descrittivo quando applicato ad un dataset ignoto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
